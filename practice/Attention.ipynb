{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPV/p2LBu3ivVn5HNdVfQ/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farheenfathimaa/practice/blob/main/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What is Attention?\n",
        "Attention mechanisms in deep learning help the model focus on the most relevant parts of the input when making predictions. They are particularly useful in tasks like language translation or text summarization, where the context of specific words or phrases matters.\n",
        "\n",
        "## Overview of the Steps\n",
        "We will implement a simple attention mechanism in the context of sequence-to-sequence models. The attention mechanism calculates attention scores, applies these scores to the input sequence, and returns a weighted sum.\n",
        "\n",
        "##Step-by-Step Guide\n",
        "###**Step 1:** Install Required Libraries\n",
        "We will use numpy for basic operations.\n",
        "\n",
        "`pip install numpy`\n",
        "\n",
        "###**Step 2:** Define the Input Data\n",
        "For this example, let's create some mock data representing a sequence of word embeddings (vectors). Each embedding could represent a word in a sentence."
      ],
      "metadata": {
        "id": "7bhd1Su47oOO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tMIbsZh7T3N",
        "outputId": "885fc87c-1b2e-4ade-a278-b8891dcdc547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence shape: (3, 4)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Mock data: sequence of word embeddings (3 words, each with a 4-dimensional vector)\n",
        "input_sequence = np.array([\n",
        "    [0.1, 0.2, 0.3, 0.4], # word 1\n",
        "    [0.2, 0.1, 0.4, 0.3], # word 2\n",
        "    [0.3, 0.5, 0.2, 0.1]  # word 3\n",
        "])\n",
        "\n",
        "print(\"Input sequence shape:\", input_sequence.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 3:** Define the Attention Mechanism\n",
        "We will calculate attention scores using a simple dot product between a \"query\" and each \"key\" (input embedding), followed by applying the softmax function to normalize the scores."
      ],
      "metadata": {
        "id": "pe1r-nsL8sXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  \"\"\"Compute the softmax of vector x.\"\"\"\n",
        "  exp_x = np.exp(x - np.max(x)) # Subtract max to prevent overflow\n",
        "  return exp_x / exp_x.sum(axis=0)\n",
        "\n",
        "def attention(query, keys):\n",
        "  \"\"\"Compute the attention scores and return the context vector.\n",
        "\n",
        "    Args:\n",
        "        query: The query vector (1D array).\n",
        "        keys: The key vectors (2D array, shape: [num_keys, key_dim]).\n",
        "\n",
        "    Returns:\n",
        "        context_vector: The weighted sum of the keys.\n",
        "        attention_weights: The attention scores (normalized).\n",
        "  \"\"\"\n",
        "  # Step 1: Compute the dot product between the query and each key\n",
        "  attention_scores = np.dot(keys, query)\n",
        "\n",
        "  # Step 2: Apply softmax to get attention weights\n",
        "  attention_weights = softmax(attention_scores)\n",
        "\n",
        "  # Step 3: Compute the context vector as the weighted sum of the keys\n",
        "  context_vector = np.sum(keys * attention_weights[:, np.newaxis], axis=0)\n",
        "\n",
        "  return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "Ng08iGO88iWS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 4:** Use the Attention Mechanism\n",
        "Let's define a query vector and use it to compute the attention scores and context vector."
      ],
      "metadata": {
        "id": "EiIm9l2CF-Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a query vector (for simplicity, we'll use a random vector)\n",
        "query_vector = np.array([0.3, 0.2, 0.4, 0.1])\n",
        "\n",
        "# Compute attention\n",
        "context, weights = attention(query_vector, input_sequence)\n",
        "\n",
        "print(\"Attention weights: \", weights)\n",
        "print(\"Context vector:\", context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU2c_tu1F5sL",
        "outputId": "8417e251-0322-4121-b9bf-35387785fba1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights:  [0.3234067  0.33660518 0.33998812]\n",
            "Context vector: [0.20165814 0.26833592 0.29966171 0.26434305]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation of the Code\n",
        "1. **Input Sequence:** `input_sequence` is a 2D array where each row represents a word embedding.\n",
        "2. **Query Vector:** `query_vector `represents what we are focusing on in the input. In practice, this could come from another part of the model.\n",
        "3. **Dot Product:** We compute the similarity between the query and each key (word embedding) using the dot product.\n",
        "4. **Softmax:** We normalize the attention scores using the softmax function.\n",
        "5. **Context Vector:** This is the weighted sum of the input embeddings, where the weights are the attention scores.\n",
        "\n",
        "---\n",
        "\n",
        "### Function: `softmax(x)`\n",
        "\n",
        "1. **`def softmax(x):`**\n",
        "   - This line defines a function called `softmax` that takes a single argument `x`. The `softmax` function will compute the softmax of the input vector `x`.\n",
        "\n",
        "2. **`\"\"\"Compute the softmax of vector x.\"\"\"`**\n",
        "   - This is a docstring, which describes what the function does. Here, it mentions that the function computes the softmax of a given vector `x`.\n",
        "\n",
        "3. **`exp_x = np.exp(x - np.max(x))`**\n",
        "   - `np.exp(x - np.max(x))`: This line computes the exponential of each element in `x`, after subtracting the maximum value in `x` from each element. Subtracting `np.max(x)` is a numerical stability trick to prevent very large exponentials that could cause overflow.\n",
        "\n",
        "4. **`return exp_x / exp_x.sum(axis=0)`**\n",
        "   - `exp_x.sum(axis=0)`: This computes the sum of all the exponentials.\n",
        "   - `exp_x / exp_x.sum(axis=0)`: This divides each exponential by the sum of all exponentials, normalizing them so that they add up to 1. This operation yields the softmax output, a probability distribution.\n",
        "\n",
        "---\n",
        "\n",
        "### Function: `attention(query, keys)`\n",
        "\n",
        "1. **`def attention(query, keys):`**\n",
        "   - This line defines the `attention` function, which takes two arguments: `query` (a 1D array) and `keys` (a 2D array).\n",
        "\n",
        "2. **`\"\"\"Compute the attention scores and return the context vector.`**\n",
        "   - This is a docstring that describes what the `attention` function does. It says that the function computes attention scores and returns a context vector and the attention weights.\n",
        "\n",
        "3. **Args:**\n",
        "   - Describes the function parameters:\n",
        "     - `query`: A 1D array representing the query vector.\n",
        "     - `keys`: A 2D array representing the key vectors. It has shape `[num_keys, key_dim]`, meaning there are `num_keys` key vectors, each of dimension `key_dim`.\n",
        "\n",
        "4. **Returns:**\n",
        "   - Describes what the function returns:\n",
        "     - `context_vector`: A weighted sum of the keys.\n",
        "     - `attention_weights`: The normalized attention scores (probabilities).\n",
        "\n",
        "---\n",
        "\n",
        "### Computing Attention\n",
        "\n",
        "5. **`attention_scores = np.dot(keys, query)`**\n",
        "   - This line computes the dot product between the `query` vector and each `key` vector in `keys`.\n",
        "   - `np.dot(keys, query)`: If `keys` is a matrix of shape `(num_keys, key_dim)` and `query` is a vector of shape `(key_dim,)`, the result is a vector of shape `(num_keys,)`. This vector represents the similarity between the `query` and each `key`.\n",
        "\n",
        "---\n",
        "\n",
        "### Applying Softmax\n",
        "\n",
        "6. **`attention_weights = softmax(attention_scores)`**\n",
        "   - This line applies the `softmax` function to the `attention_scores` to normalize them. The `attention_weights` will be a vector of probabilities, all adding up to 1. Each probability indicates the importance of the corresponding key vector relative to the query.\n",
        "\n",
        "---\n",
        "\n",
        "### Computing the Context Vector\n",
        "\n",
        "7. **`context_vector = np.sum(keys * attention_weights[:, np.newaxis], axis=0)`**\n",
        "   - `attention_weights[:, np.newaxis]`: This reshapes `attention_weights` from shape `(num_keys,)` to shape `(num_keys, 1)`, so we can broadcast it over the `keys` matrix.\n",
        "   - `keys * attention_weights[:, np.newaxis]`: This line scales each `key` vector by its corresponding attention weight. The result is a weighted set of key vectors.\n",
        "   - `np.sum(..., axis=0)`: This sums the weighted key vectors along the first axis, resulting in a single vector called `context_vector`. The `context_vector` is a weighted sum of the key vectors, where the weights are the attention scores.\n",
        "\n",
        "---\n",
        "\n",
        "### Returning the Result\n",
        "\n",
        "8. **`return context_vector, attention_weights`**\n",
        "   - This line returns two values:\n",
        "     - `context_vector`: The final weighted sum of the key vectors.\n",
        "     - `attention_weights`: The attention scores, which are normalized probabilities indicating the relevance of each key vector to the query.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "1. **`softmax(x)`**: Computes the softmax of the input vector `x`, converting it into a probability distribution.\n",
        "2. **`attention(query, keys)`**: Computes attention scores based on the dot product between the `query` and `keys`. It normalizes these scores using softmax to get attention weights, then computes a `context_vector` as the weighted sum of the `keys`.\n",
        "\n",
        "\n",
        "### Next Steps\n",
        "1. **Extend to Multiple Queries**: In real scenarios, you may have multiple queries, keys, and values.\n",
        "2. **Integrate with Deep Learning Frameworks**: Use TensorFlow or PyTorch to work with real datasets and models.\n",
        "3. **Explore Advanced Attention Mechanisms**: Study \"Scaled Dot-Product Attention\" or \"Multi-Head Attention\" used in Transformer models.\n"
      ],
      "metadata": {
        "id": "lDQlvBsOHTGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright! Let's extend the basic attention mechanism into something more complex and closer to real-world usage, such as the **Scaled Dot-Product Attention** used in Transformer models. We will also touch on how **Multi-Head Attention** works.\n",
        "\n",
        "---\n",
        "\n",
        "## Scaled Dot-Product Attention\n",
        "Scaled Dot-Product Attention is the core of attention mechanisms in models like the Transformer. The key differences from our basic attention are:\n",
        "1. We have separate **query**, **key**, and **value** vectors.\n",
        "2. The attention scores are scaled by the square root of the key dimensionality to maintain numerical stability.\n",
        "3. We can apply multiple queries at once.\n",
        "\n",
        "### Mathematical Formulation\n",
        "The attention mechanism is given by:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "---\n",
        "\n",
        "### Step-by-Step Implementation\n",
        "\n",
        "1. **Install Libraries**\n",
        "   We'll use `numpy` for matrix operations and `scipy` for additional utilities if needed.\n",
        "   ```bash\n",
        "   pip install numpy\n",
        "   ```\n",
        "\n",
        "2. **Implement Scaled Dot-Product Attention**\n",
        "   ```python\n",
        "   import numpy as np\n",
        "\n",
        "   def scaled_dot_product_attention(query, key, value):\n",
        "       \"\"\"\n",
        "       Compute the Scaled Dot-Product Attention.\n",
        "\n",
        "       Args:\n",
        "           query: The query matrix (shape: [batch_size, num_queries, d_k])\n",
        "           key: The key matrix (shape: [batch_size, num_keys, d_k])\n",
        "           value: The value matrix (shape: [batch_size, num_keys, d_v])\n",
        "\n",
        "       Returns:\n",
        "           output: The context matrix (shape: [batch_size, num_queries, d_v])\n",
        "           attention_weights: The attention weights (shape: [batch_size, num_queries, num_keys])\n",
        "       \"\"\"\n",
        "       # Step 1: Compute the dot product of query and key, then scale by sqrt(d_k)\n",
        "       d_k = query.shape[-1]\n",
        "       scores = np.matmul(query, key.transpose(0, 2, 1)) / np.sqrt(d_k)\n",
        "\n",
        "       # Step 2: Apply the softmax function to normalize the scores\n",
        "       attention_weights = softmax(scores, axis=-1)\n",
        "\n",
        "       # Step 3: Compute the weighted sum of the values\n",
        "       output = np.matmul(attention_weights, value)\n",
        "\n",
        "       return output, attention_weights\n",
        "\n",
        "   def softmax(x, axis=None):\n",
        "       \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
        "       exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
        "       return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
        "   ```\n",
        "\n",
        "### Explanation\n",
        "1. **`query`, `key`, `value`**: These matrices are 3D arrays representing multiple queries, keys, and values. The shape of these arrays is `[batch_size, num_queries/keys/values, d_k/d_v]`, where:\n",
        "   - `batch_size` is the number of sequences being processed in parallel.\n",
        "   - `d_k` is the dimensionality of the keys and queries.\n",
        "   - `d_v` is the dimensionality of the values.\n",
        "\n",
        "2. **Scaling**: We divide the dot product by the square root of `d_k` to stabilize the gradients.\n",
        "\n",
        "3. **Softmax**: We apply softmax to get normalized attention scores.\n",
        "\n",
        "4. **Output**: We compute the context by taking the weighted sum of the value vectors using the attention weights.\n",
        "\n",
        "---\n",
        "\n",
        "### Multi-Head Attention\n",
        "Multi-Head Attention allows the model to attend to different parts of the sequence simultaneously by splitting the queries, keys, and values into multiple heads.\n",
        "\n",
        "#### Implementation of Multi-Head Attention\n",
        "1. **Understanding Multi-Head Attention**: Instead of computing attention once, we split the queries, keys, and values into multiple \"heads,\" each of which performs scaled dot-product attention independently. We then concatenate these outputs and linearly project them to the desired dimensionality.\n",
        "\n",
        "2. **Implement Multi-Head Attention**\n",
        "   ```python\n",
        "   class MultiHeadAttention:\n",
        "       def __init__(self, num_heads, d_model):\n",
        "           self.num_heads = num_heads\n",
        "           self.d_model = d_model\n",
        "           self.depth = d_model // num_heads\n",
        "\n",
        "           # Weight matrices for linear transformations\n",
        "           self.W_q = np.random.randn(d_model, d_model)\n",
        "           self.W_k = np.random.randn(d_model, d_model)\n",
        "           self.W_v = np.random.randn(d_model, d_model)\n",
        "           self.W_o = np.random.randn(d_model, d_model)\n",
        "\n",
        "       def split_heads(self, x, batch_size):\n",
        "           \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
        "           x = x.reshape(batch_size, -1, self.num_heads, self.depth)\n",
        "           return x.transpose(0, 2, 1, 3)  # [batch_size, num_heads, seq_len, depth]\n",
        "\n",
        "       def call(self, query, key, value):\n",
        "           batch_size = query.shape[0]\n",
        "\n",
        "           # Linear projections\n",
        "           Q = np.dot(query, self.W_q)\n",
        "           K = np.dot(key, self.W_k)\n",
        "           V = np.dot(value, self.W_v)\n",
        "\n",
        "           # Split into multiple heads\n",
        "           Q = self.split_heads(Q, batch_size)\n",
        "           K = self.split_heads(K, batch_size)\n",
        "           V = self.split_heads(V, batch_size)\n",
        "\n",
        "           # Compute scaled dot-product attention for each head\n",
        "           context, attention_weights = scaled_dot_product_attention(Q, K, V)\n",
        "\n",
        "           # Concatenate heads and project the output\n",
        "           context = context.transpose(0, 2, 1, 3).reshape(batch_size, -1, self.d_model)\n",
        "           output = np.dot(context, self.W_o)\n",
        "\n",
        "           return output, attention_weights\n",
        "   ```\n",
        "\n",
        "### Explanation\n",
        "1. **Initialization**: We define a class `MultiHeadAttention` with the number of heads (`num_heads`) and the total dimensionality (`d_model`).\n",
        "2. **Weight Matrices**: We create weight matrices `W_q`, `W_k`, `W_v`, and `W_o` for linear transformations of the input queries, keys, and values.\n",
        "3. **Splitting Heads**: We split the input into multiple heads and transpose the dimensions to prepare for parallel computation.\n",
        "4. **Attention for Each Head**: We compute the scaled dot-product attention for each head in parallel.\n",
        "5. **Concatenation**: We concatenate the output of all heads and project it to the desired dimensionality using `W_o`.\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps\n",
        "1. **Integrate with Deep Learning Frameworks**: Use TensorFlow or PyTorch to take advantage of GPU acceleration and work with real datasets.\n",
        "2. **Explore the Transformer Model**: Study how these attention mechanisms are combined with feed-forward layers, positional encoding, and other components to build models like BERT and GPT.\n",
        "\n",
        "Would you like an example of how to implement this using TensorFlow or PyTorch, or do you have another specific focus in mind?"
      ],
      "metadata": {
        "id": "UGuUbSGCIfc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "import numpy as np\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value):\n",
        "  \"\"\"\n",
        "  Compute the Scaled Dot-Product Attention.\n",
        "\n",
        "  Args:\n",
        "      query: The query matrix (shape: [batch_size, num_queries, d_k])\n",
        "      key: The key matrix (shape: [batch_size, num_keys, d_k])\n",
        "      value: The value matrix (shape: [batch_size, num_keys, d_v])\n",
        "\n",
        "  Returns:\n",
        "      output: The context matrix (shape: [batch_size, num_queries, d_v])\n",
        "      attention_weights: The attention weights (shape: [batch_size, num_queries, num_keys])\n",
        "  \"\"\"\n",
        "  # Step 1: Compute the dot product of query and key, then scale by sqrt(d_k)\n",
        "  d_k = query.shape[-1]\n",
        "  scores = np.matmul(query, key.transpose(0, 2, 1)) / np.sqrt(d_k)\n",
        "\n",
        "  # Step 2: Apply the softmax function to normalize the scores\n",
        "  attention_weights = softmax(scores, axis=-1)\n",
        "\n",
        "  # Step 3: Compute the weighted sum of the values\n",
        "  output = np.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights\n",
        "\n",
        "def softmax(x, axis=None):\n",
        "  \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
        "  exp_x = np.exp(x - np.max(x, axis = axis, keepdims=True))\n",
        "  return exp_x / np.sum(exp_x, axis=axis, keepdims=True)"
      ],
      "metadata": {
        "id": "Mb0T74bTUU38"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MultiHeadAttention\n",
        "class MultiHeadAttention:\n",
        "    def __init__(self, num_heads, d_model):\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        self.depth = d_model // num_heads\n",
        "\n",
        "        # Weight matrices for linear transformations\n",
        "        self.W_q = np.random.randn(d_model, d_model)\n",
        "        self.W_k = np.random.randn(d_model, d_model)\n",
        "        self.W_v = np.random.randn(d_model, d_model)\n",
        "        self.W_o = np.random.randn(d_model, d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
        "        x = x.reshape(batch_size, -1, self.num_heads, self.depth)\n",
        "        return x.transpose(0, 2, 1, 3)  # [batch_size, num_heads, seq_len, depth]\n",
        "\n",
        "    def call(self, query, key, value):\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # Linear projections\n",
        "        Q = np.dot(query, self.W_q)\n",
        "        K = np.dot(key, self.W_k)\n",
        "        V = np.dot(value, self.W_v)\n",
        "\n",
        "        # Split into multiple heads\n",
        "        Q = self.split_heads(Q, batch_size)\n",
        "        K = self.split_heads(K, batch_size)\n",
        "        V = self.split_heads(V, batch_size)\n",
        "\n",
        "        # Compute scaled dot-product attention for each head\n",
        "        context, attention_weights = scaled_dot_product_attention(Q, K, V)\n",
        "\n",
        "        # Concatenate heads and project the output\n",
        "        context = context.transpose(0, 2, 1, 3).reshape(batch_size, -1, self.d_model)\n",
        "        output = np.dot(context, self.W_o)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "lntazdz_WMTT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how to implement Scaled Dot-Product Attention and Multi-Head Attention using TensorFlow. We’ll walk through the complete implementation, showing how to leverage TensorFlow’s capabilities for building and training models.\n",
        "\n",
        "---\n",
        "\n",
        "## Implementation Using TensorFlow\n",
        "\n",
        "### Step 1: Install TensorFlow\n",
        "If you haven’t already installed TensorFlow, you can do so with:\n",
        "```bash\n",
        "pip install tensorflow\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Step 2: Import Libraries\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Step 3: Scaled Dot-Product Attention in TensorFlow\n",
        "We’ll start by implementing the Scaled Dot-Product Attention function.\n",
        "\n",
        "```python\n",
        "def scaled_dot_product_attention(query, key, value):\n",
        "    \"\"\"\n",
        "    Calculate the Scaled Dot-Product Attention.\n",
        "    \n",
        "    Args:\n",
        "        query: Query tensor of shape (..., seq_len_q, depth)\n",
        "        key: Key tensor of shape (..., seq_len_k, depth)\n",
        "        value: Value tensor of shape (..., seq_len_v, depth_v)\n",
        "        \n",
        "    Returns:\n",
        "        output: The attention output of shape (..., seq_len_q, depth_v)\n",
        "        attention_weights: The attention weights of shape (..., seq_len_q, seq_len_k)\n",
        "    \"\"\"\n",
        "    # Step 1: Compute the dot product between query and key\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # Step 2: Scale the dot product by sqrt of key dimension\n",
        "    dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # Step 3: Apply softmax to get the attention weights\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    # Step 4: Compute the weighted sum of the values\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output, attention_weights\n",
        "```\n",
        "\n",
        "### Explanation\n",
        "- **`tf.matmul(query, key, transpose_b=True)`**: Computes the dot product between the query and key, transposing the key matrix to align dimensions.\n",
        "- **`dk = tf.cast(tf.shape(key)[-1], tf.float32)`**: Gets the dimensionality of the keys and converts it to `float32` for scaling.\n",
        "- **`tf.math.sqrt(dk)`**: Computes the square root for scaling.\n",
        "- **`tf.nn.softmax`**: Normalizes the attention scores using softmax.\n",
        "- **`tf.matmul(attention_weights, value)`**: Applies the attention weights to the values.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 4: Multi-Head Attention in TensorFlow\n",
        "We’ll use TensorFlow layers to create the Multi-Head Attention mechanism.\n",
        "\n",
        "```python\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % num_heads == 0  # Ensure that d_model is divisible by num_heads\n",
        "\n",
        "        self.depth = d_model // num_heads\n",
        "\n",
        "        # Linear layers for query, key, and value\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        # Output linear layer\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n",
        "\n",
        "    def call(self, query, key, value):\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # Linear projections\n",
        "        query = self.wq(query)  # (batch_size, seq_len, d_model)\n",
        "        key = self.wk(key)      # (batch_size, seq_len, d_model)\n",
        "        value = self.wv(value)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Split into multiple heads\n",
        "        query = self.split_heads(query, batch_size)  # (batch_size, num_heads, seq_len, depth)\n",
        "        key = self.split_heads(key, batch_size)      # (batch_size, num_heads, seq_len, depth)\n",
        "        value = self.split_heads(value, batch_size)  # (batch_size, num_heads, seq_len, depth)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        context, attention_weights = scaled_dot_product_attention(query, key, value)\n",
        "\n",
        "        # Concatenate heads\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, depth)\n",
        "        context = tf.reshape(context, (batch_size, -1, self.d_model))  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Final linear layer\n",
        "        output = self.dense(context)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        return output, attention_weights\n",
        "```\n",
        "\n",
        "### Explanation\n",
        "1. **Initialization**:\n",
        "   - `d_model`: Total dimensionality of the model.\n",
        "   - `num_heads`: Number of attention heads.\n",
        "   - `self.depth = d_model // num_heads`: Depth of each attention head.\n",
        "   - Linear layers (`Dense`) are used to project the queries, keys, and values.\n",
        "\n",
        "2. **`split_heads` Function**: Splits the input tensor into multiple heads and transposes the dimensions for parallel computation.\n",
        "\n",
        "3. **`call` Method**:\n",
        "   - Projects the inputs using linear layers to get queries, keys, and values.\n",
        "   - Splits them into multiple heads.\n",
        "   - Computes scaled dot-product attention for each head.\n",
        "   - Concatenates the outputs and applies a final linear layer.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 5: Testing Multi-Head Attention\n",
        "You can test the `MultiHeadAttention` layer as follows:\n",
        "\n",
        "```python\n",
        "# Define input tensors\n",
        "batch_size = 2\n",
        "seq_len = 5\n",
        "d_model = 8\n",
        "num_heads = 2\n",
        "\n",
        "query = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "key = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "value = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "\n",
        "# Initialize and call the MultiHeadAttention layer\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "output, attention_weights = mha(query, key, value)\n",
        "\n",
        "print(\"Output shape:\", output.shape)  # (batch_size, seq_len, d_model)\n",
        "print(\"Attention weights shape:\", attention_weights.shape)  # (batch_size, num_heads, seq_len, seq_len)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps\n",
        "1. **Integrate with Transformer Architecture**: Multi-Head Attention is a crucial component of the Transformer model. You can combine it with positional encoding, feed-forward networks, and layer normalization to build a complete Transformer.\n",
        "2. **Train on Real Data**: Use TensorFlow’s `tf.data` API to load and preprocess datasets for tasks like machine translation, text classification, or text summarization.\n",
        "3. **Experiment with Hyperparameters**: Adjust `d_model` and `num_heads` to see how they impact performance.\n",
        "\n",
        "Would you like more guidance on building a full Transformer model or on training a model using a real dataset?"
      ],
      "metadata": {
        "id": "ePBpC9sdUVm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 2**"
      ],
      "metadata": {
        "id": "JyCDvWVUQjkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "tx2uYuLfGiqk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 3**"
      ],
      "metadata": {
        "id": "gIn_L9NgQqc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        "  \"\"\"\n",
        "  Calculate the Scaled Dot-Product Attention.\n",
        "\n",
        "  Args:\n",
        "      query: Query tensor of shape (..., seq_len_q, depth)\n",
        "      key: Key tensor of shape (..., seq_len_k, depth)\n",
        "      value: Value tensor of shape (..., seq_len_v, depth_v)\n",
        "\n",
        "  Returns:\n",
        "      output: The attention output of shape (..., seq_len_q, depth_v)\n",
        "      attention_weights: The attention weights of shape (..., seq_len_q, seq_len_k)\n",
        "  \"\"\"\n",
        "  # Step 1: Compute the dot product between query and key\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # Step 2: Scale the dot product by sqrt of key dimension\n",
        "  dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # Step 3: Apply softmax to get the attention weights\n",
        "  attention_weights =tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "  # Step 4: Compute the weighted sum of the values\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "metadata": {
        "id": "GlcPaGquJb13"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 4**"
      ],
      "metadata": {
        "id": "-K2OEHb2Qtz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.depth = d_model // num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth) and transpose the result.\"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n",
        "\n",
        "    def call(self, query, key, value, mask=None):\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # Linear projections\n",
        "        query = self.wq(query)  # (batch_size, seq_len, d_model)\n",
        "        key = self.wk(key)      # (batch_size, seq_len, d_model)\n",
        "        value = self.wv(value)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Split into multiple heads\n",
        "        query = self.split_heads(query, batch_size)  # (batch_size, num_heads, seq_len, depth)\n",
        "        key = self.split_heads(key, batch_size)      # (batch_size, num_heads, seq_len, depth)\n",
        "        value = self.split_heads(value, batch_size)  # (batch_size, num_heads, seq_len, depth)\n",
        "\n",
        "        # Apply scaled dot-product attention\n",
        "        context, attention_weights = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        # Concatenate the heads\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, depth)\n",
        "        context = tf.reshape(context, (batch_size, -1, self.d_model))  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Final linear layer\n",
        "        output = self.dense(context)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        return output, attention_weights\n"
      ],
      "metadata": {
        "id": "rhK38WqtMNRR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 5**"
      ],
      "metadata": {
        "id": "eGxkvVrZQwQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input tensors\n",
        "batch_size = 2\n",
        "seq_len = 5\n",
        "d_model = 8\n",
        "num_heads = 2\n",
        "\n",
        "query = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "key = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "value = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "\n",
        "# Initialize and call the MultiHeadAttention layer\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "output, attention_weights = mha(query, key, value)\n",
        "\n",
        "print(\"Output shape:\", output.shape) # (batch_size, seq_len, d_model)\n",
        "print(\"Attention weights shape: \", attention_weights.shape) # (batch_size, num_heads, seq_len, seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "U3Kw99PNMavY",
        "outputId": "f3e1434a-2088-4911-fcfc-fd35b4570f10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Exception encountered when calling MultiHeadAttention.call().\n\n\u001b[1mscaled_dot_product_attention() takes 3 positional arguments but 4 were given\u001b[0m\n\nArguments received by MultiHeadAttention.call():\n  • query=tf.Tensor(shape=(2, 5, 8), dtype=float32)\n  • key=tf.Tensor(shape=(2, 5, 8), dtype=float32)\n  • value=tf.Tensor(shape=(2, 5, 8), dtype=float32)\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9551fd21c9cd>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Initialize and call the MultiHeadAttention layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-515df4a0b126>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Apply scaled dot-product attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Concatenate the heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling MultiHeadAttention.call().\n\n\u001b[1mscaled_dot_product_attention() takes 3 positional arguments but 4 were given\u001b[0m\n\nArguments received by MultiHeadAttention.call():\n  • query=tf.Tensor(shape=(2, 5, 8), dtype=float32)\n  • key=tf.Tensor(shape=(2, 5, 8), dtype=float32)\n  • value=tf.Tensor(shape=(2, 5, 8), dtype=float32)\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps to Build a Transformer Model Using a Real Dataset\n",
        "\n",
        "### Step 1: Load and Preprocess the Dataset\n",
        "- Choose a real-world dataset suitable for a sequence-to-sequence task, such as language translation (e.g., English to French).\n",
        "- Tokenize and encode the text into sequences of integers.\n",
        "- Pad or truncate sequences to a fixed length.\n",
        "\n",
        "### Step 2: Create Positional Encoding\n",
        "- Implement positional encoding to give the model information about the relative position of tokens in a sequence.\n",
        "\n",
        "### Step 3: Define the Attention Mechanisms\n",
        "- Implement the scaled dot-product attention and multi-head attention layers.\n",
        "\n",
        "### Step 4: Build the Transformer Model\n",
        "- Create the encoder and decoder layers using attention mechanisms and feed-forward networks.\n",
        "- Combine these components into the complete Transformer model.\n",
        "\n",
        "### Step 5: Define a Loss Function and Optimizer\n",
        "- Use an appropriate loss function, such as categorical cross-entropy, and an optimizer like Adam.\n",
        "\n",
        "### Step 6: Train the Model\n",
        "- Train the model on your dataset, monitor the loss, and adjust hyperparameters as needed.\n",
        "- Evaluate the model on a validation set to check its performance.\n",
        "\n",
        "### Step 7: Test the Model\n",
        "- Use the trained model to generate predictions and evaluate its performance on unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "## Code to Implement a Transformer Model (Full Example)\n",
        "\n",
        "### Step 1: Load and Preprocess the Dataset\n",
        "For this example, let's use the TensorFlow Datasets library to load the \"English-German\" translation dataset.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the dataset\n",
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
        "train_examples, val_examples = examples['train'], examples['validation']\n",
        "\n",
        "# Function to preprocess the text\n",
        "def tokenize_pairs(pt, en):\n",
        "    pt = tokenizer_pt.encode(pt.numpy())\n",
        "    en = tokenizer_en.encode(en.numpy())\n",
        "    return pt, en\n",
        "\n",
        "# Tokenizers (you may need to download and set up SentencePiece or use another tokenizer)\n",
        "# NOTE: You would need to implement or load tokenizers as appropriate for your dataset.\n",
        "```\n",
        "\n",
        "### Step 2: Create Positional Encoding\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # Apply sin to even indices and cos to odd indices\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "```\n",
        "\n",
        "### Step 3: Implement Scaled Dot-Product Attention and Multi-Head Attention\n",
        "```python\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "    dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "    return output, attention_weights\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % num_heads == 0\n",
        "        self.depth = d_model // num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, query, key, value, mask):\n",
        "        batch_size = tf.shape(query)[0]\n",
        "        query = self.split_heads(self.wq(query), batch_size)\n",
        "        key = self.split_heads(self.wk(key), batch_size)\n",
        "        value = self.split_heads(self.wv(value), batch_size)\n",
        "\n",
        "        context, attention_weights = scaled_dot_product_attention(query, key, value, mask)\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])\n",
        "        context = tf.reshape(context, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(context)\n",
        "        return output, attention_weights\n",
        "```\n",
        "\n",
        "### Step 4: Build the Transformer Model\n",
        "This part is a bit more involved. The Transformer model consists of an encoder and a decoder.\n",
        "\n",
        "```python\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "                 target_vocab_size, pe_input, pe_target):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input)\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target)\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "        final_output = self.final_layer(dec_output)\n",
        "        return final_output, attention_weights\n",
        "```\n",
        "\n",
        "### Step 5: Define Loss Function and Optimizer\n",
        "```python\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Step 6: Train the Model\n",
        "```python\n",
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS}')\n",
        "    # Implement training loop here\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7lHA8Ik8Udc4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9MfoVGCS2Qx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}